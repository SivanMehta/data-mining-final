---
title: "Analysis Random Forest"
author: "Mary St John"
date: "April 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
```

### Loading the data and cleaning it
```{r}
flights2015_clean_s <- read.csv("~/_CMU/Curr Sem 17 Spring/Data Mining/Final/data/flights2015_clean_s.csv")
flights2015_clean_u <- read.csv("~/_CMU/Curr Sem 17 Spring/Data Mining/Final/data/flights2015_clean_u.csv")
## Taking out repeat columns
flights2015_cleaner = flights2015_clean_s[,-which(names(flights2015_clean_s) %in% c("YEAR", "FL_DATE",
                          "ORIGIN_AIRPORT_SEQ_ID", "X1", "X" , "ORIGIN_AIRPORT_ID", "ORIGIN",
                          "ORIGIN_STATE_ABR", "DEST_AIRPORT_SEQ_ID", "DEST", "DEST_STATE_ABR",
                          "UNIQUE_CARRIER", "DEST_AIRPORT_ID", ""))]
getDays = function(months, days){
  monthDays = c(31,28,31,30,31,30,31,31,30,31,30,31)
  cumdays <<- rep(0, length(days))
  for (i in 1:length(months)){
    if (months[i] == 0) {cumdays[i] <<- days[i]}
    else{
      cumdays[i] = sum(monthDays[1:(months[i]-1)])+days[i]
    }
  }
  return(cumdays)
}

flights2015_cleaner$DAY = getDays(flights2015_cleaner$MONTH, flights2015_cleaner$DAY_OF_MONTH)
response = flights2015_clean_u[,which(colnames(flights2015_clean_u) == "DEP_DEL15")]
flights15 = cbind("DEP_DEL15" = response, flights2015_cleaner)
naflights15 = na.omit(flights15)[,-2]
naresponse = as.double(naflights15[,1])
factors = c("MONTH, DAY_OF_WEEK")
# This does not work
for (i in factors){
  idx = which(names(flights15) == factors[i])
  naflights15[,idx] = as.factor(flights15[,idx])
}

base_rate = mean(naresponse)
```

### Test and Training set
```{r}
set.seed(1)
train.idx = sample(1:nrow(naflights15), floor(nrow(naflights15)/(5/4)), replace = FALSE)
train = naflights15[train.idx,]
test = naflights15[-train.idx,]
x.train = naflights15[train.idx,-1]
y.train = ifelse(naresponse[train.idx] == 0, 0, 1)
x.test = naflights15[-train.idx,-1]
y.test = ifelse(naresponse[-train.idx] == 0, 0, 1)
```


### Linear Model
```{r}
fit_lm = lm(DEP_DEL15 ~ ., data = train)
predslm = predict(fit_lm, newdata = test)
errTest_lm = mean((predslm - test[,1])^2) #.1320 < base rate!
```

# Lasso
```{r}
fit_lasso = cv.glmnet(as.matrix(x.train), y.train)

predsLasso_train = predict(fit_lasso, newx = as.matrix(x.train), type = "response", s = fit_lasso$lambda.1se)
predsLasso_test = predict(fit_lasso, newx = as.matrix(x.test), type = "response", s = fit_lasso$lambda.1se) 
errTrain_lasso = mean((predsLasso_train - y.train)^2) #.1346
errTest_lasso = mean((predsLasso_test - y.test)^2) # .1331

coeffs = which(coefficients(fit_lasso) != 0)[-1] - 1 #There's only one variable in this model
```

# GAM
## Make a gam using the  variables selected from Lasso
```{r}
library(mgcv)
fit_gam = gam(train$DEP_DEL15 ~ factor(MONTH) + factor(AIRLINE_ID) + factor(FL_NUM) + factor(ORIGIN_WAC) +
              s(CRS_DEP_TIME) + s(CRS_ELAPSED_TIME) + factor(DISTANCE_GROUP) + DAY, 
              data = train, family = "binomial")
predsGam = predict(fit_gam, newdata = test)
errTest_gam = mean((predsGam - y.test)^2)
```

# GLM
```{r}
fit_glm = glm(DEP_DEL15 ~ ., data = train, family='binomial')
guess_test = predict(fit_glm, newdata = test, type='response')
errTrain_glm = mean((fitted(fit_glm) - y.train)^2) # .1329
errTest_glm = mean((guess_test - y.test)^2) # .1319
```


#Fit a Random Forest
```{r}
library(randomForest)
rf = randomForest(as.factor(DEP_DEL15)~.,data = train, importance=TRUE)
errTrain.rf = mean(y.train == rf$predicted) # .1725 Not good
if (errTrain.rf > .5){errTrain.rf = 1 - errTrain.rf}
testPreds = predict(rf, newdata = test, type = "response")
errTest.rf = mean(y.test == testPreds)
if (errTest.rf > .5){errTest.rf = 1 - errTest.rf} # .1686 Not good
```

# LDA
```{r}
library(MASS)
fit_lda = lda(x.train,y.train)
yhat_lda = predict(fit_lda,newdata = x.test)$class
misclass_rate_lda = mean(yhat_lda!=y.test) #.1652 Not good

#Build the transformed coordinates for the training and test data, in case you need them
z_train = x.train%*%fit_lda$scaling
z_test = x.test%*%fit_lda$scaling

plot(z_train[,1],z_train[,2], pch=as.character(y.train), col = y.train+1)
```

# SVM
```{r}
fit_svm_linear = tune(svm,y~.,data=subsample,scale=FALSE, kernel="linear", 
                      ranges=list(cost=c(4.05, 4.1, 4.15)))
```

# Naive Bayes
```{r}
library("e1071")
y.train = as.factor(y.train)
fit_naive_bayes = naiveBayes(x.train, y.train)
guess_test = predict(fit_naive_bayes, newdata = x.test)
errTrain_naive_bayes = mean((fitted(fit_naive_bayes) - y.train)^2) # .1329
errTest_naive_bayes = mean((as.integer(guess_test) - y.test)^2) # .1319
```

